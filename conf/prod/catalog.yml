# Here you can define all your data sets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html
#
# We support interacting with a variety of data stores including local file systems, cloud, network and HDFS
#
# An example data set definition can look as follows:
#
# The Data Catalog supports being able to reference the same file using two different Dataset implementations
# (transcoding), templating and a way to reuse arguments that are frequently repeated. See more here:
# https://docs.kedro.org/en/stable/data/data_catalog.html


"{namespace}.preprocessed_companies":
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/prod/{namespace}/preprocessed_companies.pq
  metadata:
    description: "A Parquet file containing preprocessed companies."

"{namespace}.preprocessed_shuttles":
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/prod/{namespace}/preprocessed_shuttles.pq
  metadata:
    description: "A Parquet file containing preprocessed shuttles."

"{namespace}.model_input_table":
  type: pandas.ParquetDataset
  filepath: data/03_primary/prod/{namespace}/model_input_table.pq

"{namespace}.{variant}.regressor":
  type: kedro_mlflow.io.models.MlflowModelTrackingDataset
  flavor: mlflow.sklearn
  artifact_path: "{namespace}/{variant}/regressor"
